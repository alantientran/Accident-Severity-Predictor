{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Traffic prediction ML project\n",
    "# Imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sklearn as sc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Feature engineering notes:\n",
    "    - Time and date\n",
    "    - Combine Vehicle continuing direction and vehicle going direction. Oncoming/incoming or same direction\n",
    "    - The weather and surface cond columns may help each other...\n",
    "    - Modify Light so that we replace 'Dark -- Unknown Lighting' with 'Dark'\n",
    "    \n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"traffic.csv\", na_values=['Unknown', 'None', 'UNKNOWN'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data.shape - 172,105 rows, 43 columns\n",
    "\n",
    "\n",
    "data['Collision Type'].value_counts()\n",
    "# 12% other, 717 unknown. We may want to use similar-case imputation\n",
    "\n",
    "data['Non-Motorist Substance Abuse'].value_counts()\n",
    "# There are only ~200 data points that actually had substance abuse, so this should be dropped.\n",
    "\n",
    "data['Driver Distracted By'].value_counts()\n",
    "# 1/5th of the dataset is missing, over half has drivers that were not distracted. Maybe there's a correlation between distracted driving and severity? Maybe we can train a subset of the data on this to reveal more interesting patterns. Or, we could inject and say that half of the missing is distracted and the other half is not distracted. Or, maybe we should just drop it.\n",
    "\n",
    "data['Drivers License State'].value_counts()\n",
    "# correlation between driving out of state lines and being at fault? are drivers closer to home truly more likely to get in an accident? Outliers - FM, NS, MP, SK, etc.\n",
    "\n",
    "data['Vehicle Movement'].value_counts()\n",
    "# We need to get creative with our encoding, such as moving quickly, moving at a slower rate, or manuvering (parking, passing, turning, etc)\n",
    "\n",
    "# This is our class label. We need to OHC different categories.\n",
    "data['Injury Severity'].value_counts()\n",
    "# the majority of the dataset isn't injured, fortunately.\n",
    "# we will just keep the 5 predictors\n",
    "    # No injury\n",
    "    # Possible\n",
    "    # Minor\n",
    "    # Serious\n",
    "    # Fatal :(\n",
    "    \n",
    "# Driver at fault was dropped because we don't think that the insurance/civil claim really determines how bad the accident is.\n",
    "# An accident is an accident.\n",
    "    \n",
    "# data['Off-Road Description'].unique() # Determine that the values in this column is not important\n",
    "# data['Driverless Vehicle'].unique() # No driverless vehicles, so column is unneeded\n",
    "# data['Parked Vehicle'].value_counts() # 2,600 parked vehicles got an in accident. Might be interesting to see if there's a correlation between that and the severity of the accident.\n",
    "# data['Related Non-Motorist'].value_counts() - There's only about 5000 fields here, it may be too little to make a discernible impact on the dataset.\n",
    "\n",
    "# Look into what the cross street and route type means\n",
    "# DROP Report Number, Local Case Number, Off-road description, Road name, Cross-street name, Driverless Vehicle, Municipality (many missing values),  Related Non-Motorist, Non-Motorist Substance Abuse, Person ID, Circumstance (??), Vehicle ID, Vehicle Make, Vehicle Model, Equiptment Problems, Location (as it combines Lat & Long)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Cleaning\n",
    "## Part 1: Removing unneeded rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature engineer new columns \"Vehicle Dir Changed\" and \"Vehicle Multiple Impacts\"\n",
    "data['Vehicle Dir Changed'] = np.where(data['Vehicle Continuing Dir'] == data['Vehicle Going Dir'], 'No', 'Yes')\n",
    "data['Vehicle Multiple Impacts'] = np.where(data['Vehicle First Impact Location'] == data['Vehicle Second Impact Location'], 'No', 'Yes')\n",
    "#Drop unnecessary data columns\n",
    "data = data.drop(columns = ['Agency Name', 'Report Number', 'Local Case Number', 'Off-Road Description', 'Road Name', 'Cross-Street Name', 'Driverless Vehicle', 'Municipality', 'Non-Motorist Substance Abuse', 'Person ID', 'Circumstance', 'Vehicle ID', 'Vehicle Make', 'Vehicle Model', 'Equipment Problems', 'Location','Driverless Vehicle', 'Vehicle Continuing Dir', 'Vehicle Going Dir', 'Route Type', 'Vehicle First Impact Location', 'Vehicle Second Impact Location', 'Related Non-Motorist', 'Drivers License State', 'Driver at Fault'], axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2: Feature engineering\n",
    "### Dealing with the Date/Time column\n",
    "We want to extrapolate out patterns from the data and time columns.\n",
    "It would be difficult to train on that column as a whole, but separately it \n",
    "can extract out useful patterns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.loc[data['Weather'] == 'RAINING', 'Light'] = data.loc[data['Weather'] == 'RAINING', 'Light'].fillna('DARK')\n",
    "data.loc[data['Weather'] == 'FOGGY', 'Light'] = data.loc[data['Weather'] == 'FOGGY', 'Light'].fillna('DARK')\n",
    "\n",
    "import datetime\n",
    "new_weekdays = []\n",
    "pos = 0\n",
    "count = 0\n",
    "for i, date in data['Crash Date/Time'].items() : \n",
    "    date_parsed = date.split(' ')\n",
    "    time = date_parsed[0].split('/')\n",
    "    obj = datetime.datetime(int(time[2]), int(time[0]), int(time[1]))\n",
    "    new_weekdays.append(obj.weekday())\n",
    "    hour = int(date_parsed[1].split(':')[0])\n",
    "\n",
    "    if pd.isnull(data['Light'][i]) :\n",
    "        if (hour < 5 or hour > 22) : \n",
    "            data['Light'][i] = 'DARK'\n",
    "        elif (hour >= 5 and hour <= 8): \n",
    "            data['Light'][i] = 'DAWN' \n",
    "        elif (hour > 8 and hour <= 15) : \n",
    "            data['Light'][i] = 'LIGHT'\n",
    "        elif (hour > 15 and hour <= 22) : \n",
    "            data['Light'][i] = 'DUSK'\n",
    "            \n",
    "data['Crash Date/Time'] = new_weekdays\n",
    "df_encoded = pd.get_dummies(data['Crash Date/Time'], columns=['Monday', 'Tuesday', 'Wednesday', 'Thursday', 'Friday', 'Saturday', 'Sunday'])\n",
    "data = pd.concat([data, df_encoded] , axis=1)\n",
    "data = data.drop(columns=['Crash Date/Time'])\n",
    "\n",
    "data.loc[data['Weather'] == 'CLEAR', 'Surface Condition'] = data.loc[data['Weather'] == 'CLEAR', 'Surface Condition'].fillna('DRY')\n",
    "data.loc[data['Weather'] == 'RAINING', 'Surface Condition'] = data.loc[data['Weather'] == 'RAINING', 'Surface Condition'].fillna('WET')\n",
    "\n",
    "data['Surface Condition'].value_counts()\n",
    "data = data.drop(columns=['Weather'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Map out ACRS Report Type to numerical "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['ACRS Report Type'] = data['ACRS Report Type'].map({'Property Damage Crash': 0, 'Injury Crash': 1, 'Fatal Crash': 2})\n",
    "data['Vehicle Dir Changed'] = data['Vehicle Dir Changed'].map({'No': 0, 'Yes': 1})\n",
    "data['Vehicle Multiple Impacts'] = data['Vehicle Multiple Impacts'].map({'No': 0, 'Yes': 1})\n",
    "\n",
    "\n",
    "data['ACRS Report Type'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reducing varation on the features for the Substance Abuse column\n",
    "#### Group into the following classes\n",
    "    * Alcohol\n",
    "    * Illicit Drug\n",
    "    * Medication\n",
    "    * None Present"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We are assuming that since the officer did not record any alcohol or drugs, \n",
    "# that the driver was not under the influence.\n",
    "\n",
    "data['Driver Substance Abuse'].fillna('NONE DETECTED', inplace=True)\n",
    "data['Driver Substance Abuse'].replace('ALCOHOL CONTRIBUTED', 'ALCOHOL', inplace=True)\n",
    "data['Driver Substance Abuse'].replace('ALCOHOL PRESENT', 'ALCOHOL', inplace=True)\n",
    "data['Driver Substance Abuse'].replace('ILLEGAL DRUG PRESENT', 'ILLICIT DRUG', inplace=True)\n",
    "data['Driver Substance Abuse'].replace('ILLEGAL DRUG CONTRIBUTED', 'ILLICIT DRUG', inplace=True)\n",
    "data['Driver Substance Abuse'].replace('COMBINATION PRESENT', 'ILLICIT DRUG', inplace=True)\n",
    "data['Driver Substance Abuse'].replace('COMBINATION CONTRIBUTED', 'ILLICIT DRUG', inplace=True)\n",
    "data['Driver Substance Abuse'].replace('COMBINED SUBSTANCE PRESENT', 'ILLICIT DRUG', inplace=True)\n",
    "data['Driver Substance Abuse'].replace('MEDICATION PRESENT', 'MEDICATION', inplace=True)\n",
    "data['Driver Substance Abuse'].replace('MEDICATION CONTRIBUTED', 'MEDICATION', inplace=True)\n",
    "data['Driver Substance Abuse'].replace('OTHER', 'NONE DETECTED', inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reducing variation on Traffic Control"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['Traffic Control'].replace('STOP SIGN', 'SIGN', inplace=True)\n",
    "data['Traffic Control'].replace('FLASHING TRAFFIC SIGNAL', 'SIGN', inplace=True)\n",
    "data['Traffic Control'].replace('YIELD SIGN', 'SIGN', inplace=True)\n",
    "data['Traffic Control'].replace('OTHER', 'SIGN', inplace=True)\n",
    "data['Traffic Control'].replace('PERSON', 'TRAFFIC SIGNAL', inplace=True)\n",
    "data['Traffic Control'].replace('WARNING SIGN', 'SIGN', inplace=True)\n",
    "data['Traffic Control'].replace('RAILWAY CROSSING DEVICE', 'SIGN', inplace=True)\n",
    "data['Traffic Control'].replace('SCHOOL ZONE SIGN DEVICE', 'SIGN', inplace=True)\n",
    "\n",
    "data['Traffic Control'].value_counts()\n",
    "data['Cross-Street Type'].value_counts()\n",
    "# data['Traffic Control'].isnull().value_counts()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Missing values on Collision Type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['Collision Type'].fillna('OTHER', inplace=True)\n",
    "data['Collision Type'].replace('SAME DIRECTION SIDESWIPE', 'SIDESWIPE', inplace=True)\n",
    "data['Collision Type'].replace('OPPOSITE DIRECTION SIDESWIPE', 'SIDESWIPE', inplace=True)\n",
    "data['Collision Type'].replace('SAME DIRECTION RIGHT TURN', 'TURNING', inplace=True)\n",
    "data['Collision Type'].replace('ANGLE MEETS LEFT TURN', 'TURNING', inplace=True)\n",
    "data['Collision Type'].replace('ANGLE MEETS RIGHT TURN', 'TURNING', inplace=True)\n",
    "data['Collision Type'].replace('SAME DIR REND LEFT TURN', 'TURNING', inplace=True)\n",
    "data['Collision Type'].replace('SAME DIR REND RIGHT TURN', 'TURNING', inplace=True)\n",
    "data['Collision Type'].replace('SAME DIR BOTH LEFT TURN', 'TURNING', inplace=True)\n",
    "data['Collision Type'].replace('OPPOSITE DIR BOTH LEFT TURN', 'HEAD ON', inplace=True)\n",
    "data['Collision Type'].replace('HEAD ON LEFT TURN', 'HEAD ON', inplace=True)\n",
    "data['Collision Type'].replace('ANGLE MEETS LEFT HEAD ON', 'HEAD ON', inplace=True)\n",
    "data['Collision Type'].replace('SAME DIRECTION LEFT TURN', 'TURNING', inplace=True)\n",
    "\n",
    "data['Collision Type'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data['Vehicle Movement'].value_counts()\n",
    "# We've decided to drop out the missing values here given that it's only 0.02% of the database\n",
    "data.dropna(subset=['Vehicle Movement'], inplace=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vehicle body type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['Vehicle Body Type'].value_counts()\n",
    "# car/station wagon/ police (non emergency)\n",
    "# van/truck\n",
    "# bus/heavy truck\n",
    "# emergency\n",
    "# motorcycle\n",
    "# non-road worthy\n",
    "data.dropna(subset=['Vehicle Body Type'], inplace=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vehicle Damage Extent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['Vehicle Damage Extent'].isna().value_counts()\n",
    "data['Vehicle Damage Extent'].value_counts()\n",
    "data.dropna(subset=['Vehicle Damage Extent'], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Driver Distracted By"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['Driver Distracted By'].value_counts()\n",
    "\n",
    "# data[(data['Driver At Fault'] == 'Yes') and (data['Driver At Fault'].isnull())]\n",
    "data[data['Driver Subs'] == 'Yes'][data['Driver Distracted By'].isnull()]['Driver Distracted By'].fillna('AT FAULT', inplace=True)\n",
    "\n",
    "data['Driver Distracted By'].value_counts()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['same_dir'] = data['Vehicle Movement'].apply(lambda x: 1 if 'SAME' in x else 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Results of the data cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"before the purge: \", data.shape)\n",
    "# data.dropna(subset=['Vehicle Movement'], inplace=True)\n",
    "\n",
    "# data.dropna(inplace=True)\n",
    "# print(\"after the purge: \", data.shape)\n",
    "\n",
    "\n",
    "\n",
    "nulls = data.isnull()\n",
    "nulls.mean(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cross street, traffic control, "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['Substance Abuse'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine learning\n",
    "## Part 1: Traditional models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'hidden' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[32], line 4\u001b[0m\n\u001b[1;32m      2\u001b[0m data_subset \u001b[38;5;241m=\u001b[39m data[\u001b[38;5;241m0\u001b[39m:\u001b[38;5;241m10000\u001b[39m]\n\u001b[1;32m      3\u001b[0m neural_net \u001b[38;5;241m=\u001b[39m MLPClassifier()\n\u001b[0;32m----> 4\u001b[0m neural_net(hidden)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'hidden' is not defined"
     ]
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2: Ensemble methods"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
